<!doctype html>
<html class="no-js" lang="zxx">

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>Learn</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Place favicon.ico in the root directory -->
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="shortcut icon" type="image/ico" href="images/favicon.ico" />
    <!-- Plugin-CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/animate.css">
    <!-- <link rel="stylesheet" href="css/magnific-popup.css"> -->
    <!-- Main-Stylesheets -->
    <link rel="stylesheet" href="css/space.css">
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/responsive.css">
    <script src="js/w3data.js"></script>
    <script src="js/modernizr-2.8.3.min.js"></script>
</head>

<body data-spy="scroll" data-target="#mainmenu">
    <div id="wrapper">
        <!--[if lt IE 8]>
            <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
        <![endif]-->
        <!--Prelloader-markup-->
        <header class="relative header-area wrap-header">
            <div class="header-bg">
                <div class="header-angle-bg header-small-angle-bg"></div>
                <div class="header-overlay hidden visible-xs header-overlay-small-angle-bg"></div>
            </div>
            <div class="preloader">
                <div class="preloader-spinner"></div>
            </div>
            <section>
                <div class="space-100"></div>
                <div class="space-40"></div>
                <div class="container">
                    <div class="row">
                        <div class="col-xs-6 col-sm-6">
                            <h1 class="text-left text-uppercase page-title-text-auto">learn</h1>
                            <hr class="red_hr">
                        </div>
                    </div>
                </div>
            </section>
        </header>
        <!--Header-area-->
        <!--Mainmenu-area-->
        <div w3-include-html="shared/navigation.html"></div>
        <!--Mainmenu-area/-->
        <section id="price">
            <div class="container">
                <div class="row">
                    <div class="col-xs-12 col-md-3">
                        <div class="panel panel-default">
                            <div class="panel-body">
                                <h4 class="text-left text-uppercase">White Papers</h4>
                                <hr class="red_hr">
                                <ul class="nav nav-pills nav-stacked">
                                    <li class="active"><a data-toggle="pill" href="#usingdata">Using Data Science to Score Marketing Content</a></li>
                                    <li><a data-toggle="pill" href="#valueinformation">The Value of Information in the Age of Big Data Continuum Data Science</a></li>
                                    <li><a data-toggle="pill" href="#standing">Standing up a Data Science Group</a></li>
                                </ul>
                            </div>
                        </div>
                        <div class="panel panel-default">
                            <div class="panel-body">
                                <h4 class="text-left text-uppercase">Blog</h4>
                                <hr class="red_hr">
                                <ul class="nav nav-pills nav-stacked">
                                    <li class="active"><a data-toggle="pill" href="#home">Debating the Issues with NLP</a></li>
                                    <li><a data-toggle="pill" href="#menu1">Revolutionary information flow finding in the common squid</a></li>
                                    <li><a data-toggle="pill" href="#menu2">Word Frequency Models: A Simple NLP Technique</a></li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div class="col-xs-12 col-md-9">
                        <div class="tab-content">
                            <div id="usingdata" class="tab-pane fade in active">
                                <h3>Using Data Science to Score Marketing Content</h3>
                                <p>Optimize your Marketing Content Strategy</p>
                                <article>
                                    <h4>Do you know how well your content is performing</h4>
                                    <br> The growth of the Internet in recent years has caused an evolution in on-line advertising. Static advertisements gave way to dynamic pop-up and banner advertisements which now, in turn, have given way to organic, or “native,” marketing content that blends in with the Internet viewing experience. This native marketing content not only adheres to the design of the surrounding content, it may provide a wide variety of informative content rather than abrupt sales appeals. And this native marketing content is presented in a various media (including video, audio, animation, slides, articles, white papers, catalogs, buyer’s guides, etc.) and on various types of web sites and platforms (including video sharing, entertainment, blogs, microblogs, email, professional networking, social networking, etc.)
                                    <br> This evolving and complex marketing environment has produced a demand for equally capable tools for evaluating the effectiveness of the wide array of content. The problem of evaluating content effectiveness falls into two major categories: Evaluating a particular content piece, and evaluating the effectiveness of an overall campaign, consisting of many content pieces.
                                    <br>
                                    <br>
                                    <h4>Evaluating a particular content piece</h4>
                                    <br> The problem of evaluating a particular content piece is challenging because, as noted above, content comes in several different media and is hosted on different types of web sites. Therefore even the metrics available to evaluate content vary. These content performance metrics may be associated with an external host platform if the content is hosted off of the home website. In this case, the hosting and the metrics are “offsite.” These offsite metrics may include number of visits, comments, likes, shares, and so forth.
                                    <br> On the other hand, the content performance metrics may be associated with the home website. In this case, the hosting and the metrics are “onsite.” These onsite metrics may include number of landing page hits and unique visits, forms completed, emails or phone calls generated from the Contact page, and sales.
                                    <br> The challenge in evaluating a particular content piece is two-fold. First, the piece needs to be accurately given credit for the activity that it generates. But what qualifies as “activity”? This brings us to the second challenge. The metrics used to describe the activity should be key performance indicators (KPIs). Offsite metrics such as visits, comments, and likes are generally less key than onsite metrics. In fact, these metrics generally do not reflect sentiment. A blog post may generate a high number of visits and comments, but they may be disagreeable. And as for the onsite metrics, hits are less key than unique visits, which in turn are less key than contacts and finally sales. Clearly, some metrics are “more key” than others.
                                    <br> The problem is that the more key the metric, the more difficult it generally is to associate with any particular content piece. For instance, accurate metrics are usually available from offsite analytics. These give measurements of the visits, comments, likes, shares, and so forth. And these metrics can be unambiguously associated with a particular content piece, but these metrics are less key.
                                    <br> On the other hand, the most important metric is sales, but rarely will a sale result from a customer interacting with a single content piece. Most customers will engage with several brand touchpoints before making a purchase decision.
                                    <br> So the important onsite metrics are difficult to associate with an individual content piece. This is particularly true when the content is hosted offsite. One strategy is to offer the customer a coupon code that they later must supply. This helps to associate offsite content with an onsite metric. Another strategy is to use the onsite analytics which provide referring website data. These referring website data contain a wealth of information but unfortunately they do not easily resolve the association problem. The referring website data provide, for example, the number of hits or pageviews associated with specific referring URLs. They may also provide search keywords used in navigating to the landing page. But the referring website data are incomplete. They include only a fraction of the hits. Also, hits and pageviews are less key than unique visits, forms completed, contacts and sales. Furthermore, some offsite content may not contain live links to the landing page. And finally, many of the URLs supplied cannot be unambiguously associated with a particular content piece. For instance, the most frequent referring website is often google.com or “Direct Request.” Nonetheless, for those URLs that can be associated with content pieces, the referring website data do provide helpful insight.
                                    <br>
                                    <br>
                                    <h4>Evaluating the effectiveness of an overall campaign</h4>
                                    <br> The evaluation of the effectiveness of an overall native content campaign needs to account for the body of content that is posted. As noted above, a wide variety of media and types of platforms are possible, and the associated content across this spectrum works together to form the overall campaign tapestry. It is possible, for instance, for a particular content piece not to score highly according to the evaluation methods discussed above, yet it could nonetheless play an important role in the campaign tapestry because it is the only content piece the campaign has to offer in a particular medium or platform.
                                    <br> Therefore evaluating the effectiveness of an overall campaign is more than merely tallying up and aggregating the individual content piece scores. Such an evaluation must account for three important attributes: quality, quantity and diversity. The quality of a campaign can be determined from the single-piece scores discussed above. The quantity, on the other hand, looks at the volume of pieces produced and posted. And finally, the diversity accounts for the breadth of the campaign, in terms of how many of the different off-site platforms, including email, are used.
                                    <br>
                                    <br>
                                    <h4>Instant Content Scoring Algorithm</h4>
                                    <br> The scoring of content, both at the content piece level and at the campaign level has several challenges. First, it is a complicated problem involving a substantial baseline of historical data. Second, even given such a baseline of data, how can the effectiveness of a particular offsite content piece be estimated using the important onsite KPIs? Third, how can campaign content scores be normalized while also allowing for substantial expansion, improvement, and maturity in a client’s online content? And finally, it is inconvenient for clients to wait for several weeks or months to accumulate the historical data. For many clients, there is a need for a rapidly-generated score. A good approach to solve all these challenges is by creating a heuristic scoring algorithm, described below.
                                    <br> At the point of initial registration, clients need to be able to view their current content scores. Since historical data will not generally be available to compute this initial score, a data scientist could design a scoring algorithm based on heuristic rules. These rules could entail best methods and practices that have been learned in the online content marketing industry. This heuristic scoring algorithm can be used at any and all times. In other words, its application is not limited to a first-use, or merely at the point of registration. Therefore this heuristic scoring algorithm can be used as part of a longer term solution, to help address the challenges in computing the long-term content score.
                                    <br> This heuristic scoring algorithm could compute component-level scores for each type of content. Here is a candidate list of the type of content, or categories, the heuristic algorithm might account for:
                                    <br>
                                    <ul>
                                        <li>Video</li>
                                        <li>Blogs</li>
                                        <li>Microblogs</li>
                                        <li>Newsletters</li>
                                        <li> Product pages (specifications, User Guides, etc.)
                                        </li>
                                        <li>Email</li>
                                        <li> Social networking
                                        </li>
                                    </ul>
                                    <br> This list merely illustrates the possibilities. For some clients there may be types of content that are not relevant. For instance, a service provider will not have product pages. It will be important for this heuristic algorithm to know the relevancy of each content type.
                                    <br> Therefore, in the data collection process, any content types that are not relevant would need to be noted as such. The data collection process will likely consist of a survey, or series of questions, answered by the client.
                                    <br> Once the data are collected, the instant content scoring algorithm takes the data as input. The instant content scoring algorithm has three basic components:
                                    <br>
                                    <ul>
                                        <li> Data formatting. The input data are prepared for use in the second component.
                                        </li>
                                        <li> Content type models. The prepared data are input to each model, for each content type, and a score is output for that particular content type. If the input data indicate that the content type is not relevant, then a “Not applicable” score is output.
                                        </li>
                                        <li> Aggregate model. The scores for each content type, output from the second component, are used together in a model that computes an overall, campaign, score.
                                        </li>
                                    </ul>
                                    <br> Therefore, the output from this heuristic algorithm is both (i) a single, normalized, aggregate score and (ii) the individual content type scores. The individual content type scores could be accessed, for example, by hovering or clicking on the aggregate score.
                                    <br>
                                    <br>
                                    <h4>Content Prescription Algorithm</h4>
                                    <br> The next logical step for users, after learning their content scores, is to learn what is their best strategy to improve and maintain their score. The content score breakdown (i.e., the scores for each specific content type) gives users ideas for improving their score. But the content score breakdown, itself, can only provide limited guidance. This is because these scores do not indicate the relative importance, or the relative cost, of each of the different content types.
                                    <br> A data scientist could construct algorithms that take as input (i) the answers to these questions, and (ii) the content scoring outputs (such as from the instant scoring content algorithms). The algorithms then compute a suggested strategy that efficiently uses the client’s resources to meet the goals, and improve the content scores.
                                    <br> Importantly, a content prescription algorithm could support a “what-if” capability, allowing the user to input a hypothetical strategy. The algorithm would take this hypothetical strategy as an input and produce as output the results of implementing that strategy.
                                    <br>
                                    <br>
                                    <h4>Long term content scoring algorithm</h4>
                                    <br> This algorithm is more challenging than the previous two because it incorporates data filtering, modeling, and tracking components. In addition to being more challenging, this algorithm requires a substantial baseline of data describing the content and describing the on-line activity (such as from Google Analytics). The data can be divided into two main categories: independent and dependent data or, more generally, input and output data.
                                    <br> The input data consist of the descriptions of the content pieces that have been posted to the Internet. For each content piece, these descriptions include three key parameters:
                                    <br>
                                    <ul>
                                        <li> The type of content piece (e.g., blog post, microblog post, email, social network post, video, web page document, newsletter, etc).
                                        </li>
                                        <li> The date of the posting.
                                        </li>
                                        <li> A metric of the relative quality or length of the content (1-10).
                                        </li>
                                    </ul>
                                    The output data consist of the results of the content postings. These fall into offsite and onsite metrics, as described in the Introduction above. As before the offsite metrics may include number of visits, comments, likes, shares, and so forth. The onsite metrics include data typically associated with the home website and may include number of landing page hits and unique visits, forms completed, emails or phone calls generated from the Contact page, and sales. The following is a real-world campaign promoting a new educational service. In this simple case study, the campaign consisted of four content pieces posted to the Internet in June of 2014:
                                    <ul>
                                        <li> A posting on a relevant blog promoting the new service.
                                        </li>
                                        <li> An advertisement on a relevant website promoting the new service.
                                        </li>
                                        <li> An advertisement on a different, relevant, website promoting the new service.
                                        </li>
                                        <li> A podcast discussing the details of the new service.
                                        </li>
                                    </ul>
                                    <h4>  Conclusion</h4>
                                    <br> Being able to effectively and efficiently measure marketing content can optimize the way marketers reach their target audience. If you know a certain piece of content works on a certain media channel, you can repeat that process, increasing revenue from your content strategy.
                                </article>
                            </div>
                            <div id="valueinformation" class="tab-pane fade">
                                <h3>The Value of Information in the Age of Big Data Continuum Data Science</h3>
                                <article>
                                    <div>
                                        <br>
                                        <h4>Introduction</h4>
                                        <br> This white paper explores how traditional models of the value of information (VoI) can be extended effectively to account for uncertainties presently inherent in gathering and analyzing big data. To illustrate the challenge, we explore the VoI an automobile manufacturer may derive by engineering a telematics system into its vehicles.
                                        <br>
                                        <br>
                                        <h4>Background</h4>
                                        <br> Let’s start by reviewing a few key basic concepts.
                                        <strong>Big data</strong>. We define<strong> big data</strong> as data that an organization cannot store, process, or analyze economically using traditional storage technologies such as relational databases or text files. This definition has three implications that matter to us here.
                                        <ol>
                                            <li>One organization’s big data may be another organization’s small data.<sup>1</sup></li>
                                            <li>Data is usually big because it has a low value per unit of storage (bit, byte, etc.), compared to the data that organizations have stored in relational databases for decades.</li>
                                            <li>The point of gathering big data is the same as gathering small data: to capture transactions represented by the data (<strong>online transaction processing</strong>, or OLTP); or to analyze the data in a way that lets the organization improve its operations (<strong>business intelligence</strong>, or BI). Sometimes these two purposes merge in <strong>operational BI</strong>. Big data is not an economic end in itself.</li>
                                        </ol>
                                        <strong>Decision analysis.</strong> Next, <strong>decision analysis</strong> is the practice of formally modeling a decision to determine rigorously the best course of action available to an individual or group <strong>decision maker</strong>. The practice dates back at least to the mid-twentieth century axiomatics of researchers such as Stanford Professors Kenneth Arrow and Ron Howard<sup>2</sup>. And while decision analysis relies on basic concepts of probability and utility that are much older, it continues to be an active area of research. For example, in recent decades cognitive scientists have catalogued <strong>cognitive biases</strong>, frequently observed departures from decision science’s prescriptions about rational decisions.<sup>3</sup> Some decision scientists have created ways to account for a decision maker’s attitude towards risk.<sup>1</sup>Others continuing in Professor Arrow’s tradition explore how best to model and improve necessarily imperfect group decision processes.<sup>5</sup> Decision analysis usually represents decisions graphically as <strong>decision trees</strong> or <strong>influence diagrams</strong>. In this paper’s examples we’ll stick with the former, because they’re likely more familiar. (The two are formally equivalent.<sup>6</sup>)
                                        <strong>The value of information.</strong> Finally, VoI is the difference between the expected value of a given decision in the absence of some piece of information, and the expected value of the same decision in the presence of that information (presumably having paid some price to receive the information). So a decision problem involving VoI models <em>two</em> decisions: whether to acquire the information, and the nominal decision the information may inform. Here is a trivial example. Suppose you consider purchasing a used car priced at $20,000. If the car is in excellent shape (and it seems to be), the Kelley Blue Book Web site tells you the car is worth $21,000. If it’s in good condition, requiring only minor repairs, it’s worth $20,000. If it’s in poor condition and requires a major repair, it’s worth $16,000. A reliable used-car valuation Web site tells you that 50% of vehicles with the same make, model, and model year are in excellent condition, 30% in good condition, and 20% in poor condition.
                                        <br> The expected value of this uninformed decision to buy is
                                        <br> 0.5 * ($21,000 – $20,000) + 0.3 * ($20,000 – 20,000) + 0.2 * ($16,000 – 20,000) = 0.5 * $1,000 + 0.3 * $0 + 0.2 * -$4,000 = $500 + $0 + -$800 = -$300
                                        <br> So buying the car without knowing what condition it’s really in would “in expectation” leave you worse off by $300. Compared to doing nothing (at an expected value of $0), that would be a bad choice.
                                        <br> Before making an offer on the car, you could insist on taking the car to a mechanic for an independent inspection. The inspection costs $200. The inspection would reveal the car’s condition with certainty. Now your decision looks like this:
                                        <br> Your expected value is now
                                        <br> -$200 + 0.5 * ($21,000 – $20,000) + 0.3 * ($20,000 – 20,000) + 0.2 * ($0) = -$200 + 0.5 * $1,000 + 0.3 * $0 + 0.2 * $0 = -$200 + $500 + $0 + $0 = $300
                                        <br> As the terms in bold suggest, you trade away a certain $200 to avoid a 20% chance of losing $4,000 (a -$800 expected value). That tradeoff is favorable enough to make your overall expected value $300, which is now better than doing nothing. So in this case the information is worth buying. (In fact, a little reflection tells you that it would be worth paying the mechanic up to $500 to inspect the car before you decide whether to buy it.)
                                        <br> Big Data’s VoI Uncertainties
                                        <br> BI specialists have long known that data warehouse (DW) end users do not reliably predict how they will eventually use the DW’s historical data. Initially they often overlook use cases entirely, and for years later may persist in significantly misjudging the value of even well-known use cases having well-understood business cases.7
                                        <br> The same uncertainties become even more acute when working with big data. Because end users generally lack experience with the data, the organization may fail entirely to recognize a valuable use case. Or, the organization may be uncertain about whether and to what degree a known use case is valuable. Furthermore, unlike BI projects, which have fairly predictable development costs (if they’re well managed), big data projects introduce two new uncertainties: whether the selected big data storage and analysis technologies will work at all, and if so how much it will cost to use them. In sum, big data is fraught with uncertainty as to implementation feasibility and cost, use cases, and use-case value. Merely deciding which of these uncertainties to reduce, by what means, and by how much, can be intimidating. This is where decision modeling incorporating VoI analysis really shines.
                                        <br> The Example of Motor Vehicle Telematics
                                        <br> What are telematics? Let’s now explore VoI opportunities in the context of an automobile manufacturer considering adding telematics to its new vehicles. Telematics in this context combine telecommunications and informatics capabilities to make an automobile part of the “Internet of things.” The vehicle sends operational data to the manufacturer, and may also receive operational instructions, software updates, etc. from the manufacturer. Ultimately the manufacturer must decide whether, when, and how to implement telematics. To inform that decision, the manufacturer may wish to gather additional information about the costs and benefits of telematics.
                                        <br> Telematics mean big data. Automotive telematics quickly become a big data challenge as the frequency with which a vehicle transmits data increases. To illustrate: one telematics system currently in production for fleets offers real-time delivery of diagnostic fault codes, fuel consumption, idle vs. work time, engine hours, odometer, temperatures, and pressures.8 So it would not be unrealistic to suppose an automotive telematics system transmits 10 four-byte numbers in a message that overall requires 100 bytes, once per time period. Suppose further that the manufacturer sells 10 million vehicles worldwide each year, and wants to track five years of telematics history (e.g. to cover the entire warranty period). At steady state the manufacturer would have 50 million vehicles reporting 100 bytes, or 5GB total, per time period. Table 1 below presents different periods and the steady-state data storage they require under these assumptions.
                                        <br>
                                        <br>
                                        <h4>Putting it all Together</h4> The decision-analysis process is less linear than this white paper suggests. In particular, there are significant interactions between different sources of uncertainty. Technology limitations can lead to decisions to scrap a use case that viewed independently appears attractive. The decision to implement one use case requiring frequent transmission of a set of metrics may dramatically reduce the cost of another, otherwise marginal use case, by satisfying its metrics requirements at little or no incremental cost.
                                        <br> Most important, several marginally attractive use cases can combine to make a much more attractive overall business case for vehicle telematics, in part because (as long as their outcomes are generally independent) aggregating many use cases pools their risks, making it unlikely that a properly executed telematics implementation will prove unprofitable. On average each use case will be marginally profitable. And over time, additional use cases for telematics data already in storage will accrue, improving the return on the telematics big data investment. This is perhaps the most surprising consequence of the fact that big data is, by definition, data that one cannot store and analyze profitably in traditional databases. In contrast with data in traditional databases, which mostly have very small sets of use cases, a key virtue of telematics data is the abundance of modestly attractive use cases these data enjoy.
                                    </div>
                                </article>
                            </div>
                            <div id="standing" class="tab-pane fade">
                                <h3>Standing up a Data Science Group</h3>
                                <p>Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam.</p>
                            </div>
                            <div id="menu3" class="tab-pane fade">
                                <h3>Menu 3</h3>
                                <p>Eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="space-40"></div>
        </section>
    </div>
    <!--Footer-area-->
    <div w3-include-html="shared/footer.html"></div>
    <!--Footer-area/-->
    <!--Vandor-JS-->
    <script src="js/jquery-1.12.4.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <!--Plugin-JS-->
    <script src="js/owl.carousel.min.js"></script>
    <script src="js/scrollUp.min.js"></script>
    <script src="js/contact-form.js"></script>
    <script src="js/wow.min.js"></script>
    <!--Main-JS-->
    <script src="js/main.js"></script>
    <script>
    w3.includeHTML();
    </script>
</body>

</html>